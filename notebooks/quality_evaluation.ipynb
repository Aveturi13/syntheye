{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Quality Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.data_utils import ImageDataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_dataset_path = \"/home/zchayav/projects/syntheye/synthetic_datasets/stylegan2_synthetic_100perclass/generated_examples.csv\"\n",
    "real_dataset_path = \"/home/zchayav/projects/syntheye/datasets/eye2gene_new_filepaths/all_baf_valid_50deg_filtered_train_0_edited.csv\"\n",
    "\n",
    "# add image transforms\n",
    "tr = transforms.Compose([transforms.Resize((512, 512)), transforms.Grayscale(), transforms.ToTensor()])\n",
    "\n",
    "# load csvs\n",
    "synthetic_dataset = ImageDataset(synthetic_dataset_path, \"file.path\", \"gene\", class_vals=\"classes.txt\", transforms=tr, class_mapping=\"classes_mapping.json\")\n",
    "real_dataset = ImageDataset(real_dataset_path, \"file.path\", \"gene\", class_vals=\"classes.txt\", transforms=tr, class_mapping=\"classes_mapping.json\")\n",
    "synth_dataloader = torch.utils.data.DataLoader(synthetic_dataset, batch_size=64)\n",
    "real_dataloader = torch.utils.data.DataLoader(real_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = torch.cat([synthetic_dataset[i][2] for i in range(25)], dim=0)\n",
    "sample_images = sample_images[:, None, :, :]\n",
    "assert sample_images.shape == (25, 1, 512, 512)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "grid = make_grid(sample_images, nrow=5)\n",
    "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = torch.cat([real_dataset[i][2] for i in range(25)], dim=0)\n",
    "sample_images = sample_images[:, None, :, :]\n",
    "assert sample_images.shape == (25, 1, 512, 512)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "grid = make_grid(sample_images, nrow=5)\n",
    "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: UMAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from babyplots import Babyplot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the real dataset in 2D\n",
    "print(\"Fitting Real Dataset\")\n",
    "real_reducer = umap.UMAP(random_state=1399, n_components=2)\n",
    "for _, _, x, y in tqdm(real_dataloader):\n",
    "    x = x.view(len(x), -1).numpy()\n",
    "    real_reducer.fit(x)\n",
    "\n",
    "print(\"Fitting Synthetic Dataset\")\n",
    "synth_reducer = umap.UMAP(random_state=1399, n_components=2)\n",
    "for _, _, x, y in tqdm(synth_dataloader):\n",
    "    x = x.view(len(x), -1).numpy()\n",
    "    synth_reducer.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the real and synthetic datasets\n",
    "real_embed = []\n",
    "for _, _, x, y in real_dataloader:\n",
    "    real_embed.append(real_reducer.transform(x.view(len(x), -1)))\n",
    "real_embed = np.concatenate(real_embed)\n",
    "\n",
    "synth_embed = []\n",
    "for _, _, x, y in synth_dataloader:\n",
    "    synth_embed.append(synth_reducer.transform(x.view(len(x), -1)))\n",
    "synth_embed = np.concatenate(synth_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.concatenate([real_embed, np.array(real_dataset.img_labels)[:, None]], axis=1), columns=[\"C1\", \"C2\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df.values[:, 0], df.values[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D feature space plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tSNE style plots of the clustering\n",
    "bp = Babyplot()\n",
    "bp.add_plot(real_embed.tolist(), \"pointCloud\", \"categories\", real_dataset.img_labels, {\"colorScale\": \"Set1\", \"showLegend\": True, \"folded\": True, \"foldedEmbedding\": real_embed.tolist(), \"size\": 5})\n",
    "bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D feature space plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tSNE style plots of the clustering\n",
    "bp = Babyplot()\n",
    "bp.add_plot(real_embed.tolist(), \"pointCloud\", \"categories\", real_dataset.img_labels, {\"colorScale\": \"Set1\", \"showLegend\": True, \"folded\": True, \"foldedEmbedding\": real_embed.tolist(), \"showAxes\": [True, True, True], \"size\": 5})\n",
    "bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = Babyplot()\n",
    "bp.add_plot(synth_embed.tolist(), \"pointCloud\", \"categories\", synthetic_dataset.img_labels, {\"colorScale\": \"Set1\", \"showLegend\": True, \"folded\": True, \"foldedEmbedding\": synth_embed.tolist(), \"showAxes\": [True, True, True], \"size\": 5})\n",
    "bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39c011865179f9bc101bf31601589dbb1b840b59bc601cec97f2e2f528c057dd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
