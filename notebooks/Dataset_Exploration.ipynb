{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780133cf",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ed967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import ImageDataset\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a428763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(dataset):\n",
    "    scan_ids = list(dataset[\"scan.id\"].unique())\n",
    "    for i in scan_ids:\n",
    "        subset = dataset[dataset[\"scan.id\"] == i]\n",
    "        idxs = list(subset.index)\n",
    "        if len(subset) > 1:\n",
    "            dataset = dataset.drop(idxs[1:], axis=0)\n",
    "    return dataset.reset_index(drop=True)\n",
    "\n",
    "def visualize_duplicates(dataset):\n",
    "    scan_ids = list(dataset[\"scan.id\"].unique())\n",
    "    for i in scan_ids:\n",
    "        subset = dataset[dataset[\"scan.id\"] == i]\n",
    "        idxs = list(subset.index)\n",
    "        if len(subset) > 1:\n",
    "            print(\"Scan ID : {}\".format(i))\n",
    "            plt.figure(figsize=(15, 6))\n",
    "            for j, k in enumerate(idxs):\n",
    "                plt.subplot(1, len(subset), j+1)\n",
    "                plt.title(\"Scan #: {}, Date: {}\".format(dataset.iloc[k][\"scan.number\"],\n",
    "                                                        dataset.iloc[k][\"date\"]))\n",
    "                img = np.array(Image.open(dataset.iloc[k][\"file.path\"]))\n",
    "                plt.imshow(img, plt.cm.gray)\n",
    "                plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "def visualize_sizes(df):\n",
    "    \n",
    "    genes, sizes = np.unique(df.gene, return_counts=True)\n",
    "    idxs = np.argsort(sizes)\n",
    "    genes = genes[idxs]\n",
    "    sizes = sizes[idxs]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(list(reversed(genes)), list(reversed(sizes)))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797079b",
   "metadata": {},
   "source": [
    "# Inspect Dataset Size and Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b66eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"datasets/eye2gene/all_baf_valid_50deg_filtered_val_0_edited.csv\")\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d31f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_csv(\"datasets/eye2gene/all_baf_valid_50deg_filtered_train_0.csv\")\n",
    "real_plus_synthetic1800 = pd.read_csv(\"datasets/syntheye/real+stylegan2_1800.csv\")\n",
    "real_plus_synthetic3600 = pd.read_csv(\"datasets/syntheye/real+stylegan2_3600.csv\")\n",
    "real_plus_syntheticRebalanced = pd.read_csv(\"datasets/syntheye/real+stylegan2_rebalanced.csv\")\n",
    "synthetic1800 = pd.read_csv(\"synthetic_datasets/stylegan2_synthetic_50perclass/generated_examples.csv\")\n",
    "synthetic3600 = pd.read_csv(\"synthetic_datasets/stylegan2_synthetic_100perclass/generated_examples.csv\")\n",
    "syntheticRebalanced = pd.read_csv(\"synthetic_datasets/stylegan2_synthetic_-1perclass/generated_examples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheticRebalanced = pd.read_csv(\"/home/zchayav/projects/stylegan2-ada-pytorch/stylegan2_synthetic_-1perclass/generated_examples.csv\")\n",
    "syntheticRebalanced[\"file.path\"] = list(map(os.path.abspath, \"synthetic_datasets/\"+syntheticRebalanced[\"file.path\"]))\n",
    "# synthetic1800.to_csv(\"synthetic_datasets/stylegan2_synthetic_50perclass/generated_examples.csv\")\n",
    "syntheticRebalanced.to_csv(\"synthetic_datasets/stylegan2_synthetic_-1perclass/generated_examples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classes.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "    \n",
    "real = real[real.gene.isin(classes)]\n",
    "real_plus_synthetic1800 = real_plus_synthetic1800[real_plus_synthetic1800.gene.isin(classes)]\n",
    "real_plus_synthetic3600 = real_plus_synthetic3600[real_plus_synthetic3600.gene.isin(classes)]\n",
    "real_plus_syntheticRebalanced = real_plus_syntheticRebalanced[real_plus_syntheticRebalanced.gene.isin(classes)]\n",
    "synthetic1800 = synthetic1800[synthetic1800.gene.isin(classes)]\n",
    "synthetic3600 = synthetic3600[synthetic3600.gene.isin(classes)]\n",
    "syntheticRebalanced = syntheticRebalanced[syntheticRebalanced.isin(classes)]\n",
    "\n",
    "visualize_sizes(real_df)\n",
    "visualize_sizes(real_plus_synthetic1800)\n",
    "visualize_sizes(real_plus_synthetic3600)\n",
    "visualize_sizes(real_plus_syntheticRebalanced)\n",
    "visualize_sizes(synthetic1800)\n",
    "visualize_sizes(synthetic3600)\n",
    "visualize_sizes(syntheticRebalanced)\n",
    "\n",
    "# dataset_df = pd.read_csv(\"datasets/syntheye/\")\n",
    "# dataset_df = dataset_df[dataset_df.gene.isin(classes)]\n",
    "# # dataset_df = dataset_df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"Unnamed: 0.1.1\"], axis=1)\n",
    "# dataset_df = dataset_df.reset_index(drop=True)\n",
    "# dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size = {}\".format(len(dataset_df)))\n",
    "print(\"Training set size = {}\".format(len(dataset_df[dataset_df.fold != -1])))\n",
    "print(\"Test set size = {}\".format(len(dataset_df[dataset_df.fold == -1])))\n",
    "print(\"Dataframe cols : {}\".format(list(dataset_df.columns)))\n",
    "print(\"Number of unique patients : {}\".format(len(dataset_df[\"patient.number\"].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc953f2",
   "metadata": {},
   "source": [
    "## Visualize duplicate images in dataset (images with same scan ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5876767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_duplicates(dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246af0c",
   "metadata": {},
   "source": [
    "## Omit duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d42ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are duplicates of images (multiple images collected for a patient) in dataframe - get rid of those\n",
    "cleaned_df = remove_duplicates(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe33bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size = {}\".format(len(cleaned_df)))\n",
    "print(\"Training set size = {}\".format(len(cleaned_df[cleaned_df.fold != -1])))\n",
    "print(\"Test set size = {}\".format(len(cleaned_df[cleaned_df.fold == -1])))\n",
    "print(\"Dataframe cols : {}\".format(list(cleaned_df.columns)))\n",
    "print(\"Number of unique patients : {}\".format(len(cleaned_df[\"patient.number\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2092c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes, counts = np.unique(dataset_df[\"gene\"], return_counts=True)\n",
    "for i, c in enumerate(classes):\n",
    "    print(\"Class: {}, Total : {} images\\n\".format(c, counts[i]))\n",
    "    c_df = dataset_df.loc[dataset_df.gene == c]\n",
    "    patient_to_image_ratio = c_df[\"patient.number\"].value_counts()\n",
    "    print(len(patient_to_image_ratio))\n",
    "    print(patient_to_image_ratio)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3526c0e",
   "metadata": {},
   "source": [
    "## Inspect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= \"datasets/faf_dataset_cleaned.csv\"\n",
    "filenames_col= \"file.path\"\n",
    "labels_col= \"gene\"\n",
    "train_classes= \"classes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = []\n",
    "resize_dim = 512\n",
    "image_transforms.append(transforms.Resize((resize_dim, resize_dim)))\n",
    "image_transforms.append(transforms.Grayscale())\n",
    "image_transforms.append(transforms.ToTensor())\n",
    "image_transforms.append(transforms.Normalize((0.5,), (0.5,)))\n",
    "image_transforms = transforms.Compose(image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(data_file, filenames_col, labels_col, [\"ABCA4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d4fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_type = None\n",
    "thresholding = \"adaptive\"\n",
    "\n",
    "img = [np.array(dataset[i][2]) for i in range(10)]\n",
    "\n",
    "# apply smoothing filter followed by thresholding \n",
    "for im in img:\n",
    "    \n",
    "    # apply filter\n",
    "    if filter_type == \"averaging\":\n",
    "        im_filtered = cv2.blur(im, (7, 7))\n",
    "    elif filter_type == \"gaussian\":\n",
    "        im_filtered = cv2.GaussianBlur(im, (5,5), 0)\n",
    "    else:\n",
    "        im_filtered = im\n",
    "    \n",
    "    # apply thresholding\n",
    "    if thresholding == \"global\":\n",
    "        ret, thresholding_map = cv2.threshold(im_filtered, 50, 1, cv2.THRESH_BINARY_INV)\n",
    "    else:\n",
    "        thresholding_map = cv2.adaptiveThreshold(im, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(im, plt.cm.gray)\n",
    "    plt.axis(\"off\"), plt.title(\"Original\")\n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(im_filtered, plt.cm.gray)\n",
    "    plt.axis(\"off\"), plt.title(\"Filtered\")\n",
    "    \n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(thresholding_map, plt.cm.gray)\n",
    "    plt.axis(\"off\"), plt.title(\"Threshold map\")\n",
    "    \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(thresholding_map*im, plt.cm.gray)\n",
    "    plt.axis(\"off\"), plt.title(\"Original * Threshold\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     x, y = np.indices((768, 768))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.scatter(x.ravel(), im.ravel())\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.scatter(y.ravel(), im.ravel())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ef72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
