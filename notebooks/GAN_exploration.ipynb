{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73a4c2c",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15933320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ea2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_utils import get_noise, get_one_hot_labels, combine_vectors, ImageDataset, show_tensor_images\n",
    "from utils.evaluation_utils import Interpolate\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de822d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539254a2",
   "metadata": {},
   "source": [
    "# Load original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5651cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "image_transforms = transforms.Compose([transforms.Resize((512, 512)), transforms.Grayscale(), transforms.ToTensor()])\n",
    "data_file = \"datasets/syntheye/faf_dataset_cleaned.csv\"\n",
    "classes = \"classes.txt\"\n",
    "dataset = ImageDataset(data_file=data_file,\n",
    "                       fpath_col_name=\"file.path\",\n",
    "                       lbl_col_name=\"gene\",\n",
    "                       class_vals=classes,\n",
    "                       transforms=image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, class_rep = np.unique(dataset.img_labels, return_counts=True)\n",
    "class_rep_df = pd.DataFrame({'Class':classes, '%':class_rep})\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.pie(class_rep, labels=classes, autopct=\"%.1f%%\", rotatelabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca13b91b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_rep_df = class_rep_df.sort_values(by=[\"%\"], ascending=False)\n",
    "np.sum(class_rep_df[\"%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c67b7",
   "metadata": {},
   "source": [
    "# Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20315343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "model_name = \"cmsggan\"\n",
    "n_classes = dataset.n_classes\n",
    "z_dim = 512\n",
    "resolution = 512\n",
    "depth = int(np.log2(resolution) - 1)\n",
    "weights_dir = \"checkpoints/data:faf_dataset_cleaned.csv_classes:classes.txt_trans:512-1-1_mod:cmsggan1-512-512_tr:1000-RAHinge-32-1-0.003-0.003-0.0-0.99/\"\n",
    "weights_file = \"model_ema_state_106.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load architecture\n",
    "from models.msggan import conditional_msggan\n",
    "gan_model = conditional_msggan.MSG_GAN(latent_size=z_dim,\n",
    "                                       mode=\"grayscale\",\n",
    "                                       depth=depth,\n",
    "                                       n_classes=n_classes,\n",
    "                                       device=\"cpu\").gen_shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "gan_model = torch.nn.DataParallel(gan_model, device_ids=[device])\n",
    "gan_model.load_state_dict(torch.load(weights_dir+weights_file, map_location=device))\n",
    "# gan_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "noise = get_noise(1, 512).to(device)\n",
    "class_enc = get_one_hot_labels(torch.tensor([1]), 36).to(device)\n",
    "combined = combine_vectors(noise, class_enc)\n",
    "# combined = (combined / combined.norm()) * (combined.shape[-1] ** 0.5)\n",
    "images = gan_model(combined)\n",
    "\n",
    "plt.imshow(images[-1].detach().cpu().numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf6034",
   "metadata": {},
   "source": [
    "## Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee782755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "class ImageEncoder_v2(Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder_v2).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "# class NoiseLayer(Module):\n",
    "#     def __init__(self, latent_size, idx=1, n_classes=36):\n",
    "#         super(NoiseLayer, self).__init__()\n",
    "#         self.latent_size = latent_size\n",
    "#         self.class_encoding = get_one_hot_labels(torch.as_tensor([idx]), n_classes)\n",
    "#         self.w = torch.nn.Parameter(torch.randn(1, self.latent_size), requires_grad=True)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         noise = torch.multiply(x, self.w)\n",
    "#         latent = combine_vectors(noise, self.class_encoding)\n",
    "#         return latent\n",
    "\n",
    "class ImageEncoder():\n",
    "    def __init__(self, latent_size=512, idx=None, n_classes=36, decoder_model=None, device=None):\n",
    "        self.device = device\n",
    "        \n",
    "        # initialize noise as update-able parameter\n",
    "        self.noise = torch.nn.Parameter(torch.randn(1, latent_size), requires_grad=True)\n",
    "        \n",
    "        # obtain class encoding (a non)\n",
    "        self.class_encoding = get_one_hot_labels(torch.tensor([idx]), n_classes)\n",
    "        \n",
    "        # initialize GAN (decoder) with the parameters frozen\n",
    "        self.decoder_model = decoder_model\n",
    "        for param in self.decoder_model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # for adjusting range of image values\n",
    "        self.image_adjustor = conditional_msggan.Generator.adjust_dynamic_range\n",
    "        \n",
    "    def plot_results(self, losses, expected_image, predicted_image):\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(np.arange(len(losses)), losses)\n",
    "        plt.title(\"Loss change over iterations\")\n",
    "        plt.xlabel(\"Iterations\"), plt.ylabel(\"Reconstruction loss\")\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(expected_image.detach().cpu().numpy(), plt.cm.gray)\n",
    "        plt.title(\"Target Image\"), plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(predicted_image.detach().cpu().numpy(), plt.cm.gray)\n",
    "        plt.title(\"Generated Image\"), plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "    def __call__(self, expected_im, lr=0.01, iterations=10, plot_losses=True, steps=1):\n",
    "        \n",
    "        # initialize optimizer and reconstruction loss\n",
    "        self.optim = torch.optim.Adam([self.noise], lr=lr)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        \n",
    "        # save losses here\n",
    "        losses = []\n",
    "        \n",
    "        # begin training\n",
    "        for i in range(1, iterations+1):\n",
    "            \n",
    "            # predict image\n",
    "            combined_latent = combine_vectors(self.noise, self.class_encoding)\n",
    "            predicted_im = self.decoder_model(combined_latent)[-1].squeeze()\n",
    "            predicted_im = self.image_adjustor(predicted_im)\n",
    "            \n",
    "            # compute loss \n",
    "            loss = self.criterion(predicted_im, expected_im.to(predicted_im.device))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # optimize \n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "            # plot error\n",
    "            if plot_losses:\n",
    "                if i % steps == 0:\n",
    "                    self.plot_results(losses, expected_im, predicted_im)\n",
    "\n",
    "        return self.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44242a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1399)\n",
    "_, _, expect_im, idx = dataset[500]\n",
    "# expect_im = transforms.RandomHorizontalFlip(p=1)(expect_im)\n",
    "encoder = ImageEncoder(idx=idx, n_classes=36, decoder_model=gan_model, device=\"cuda:1\")\n",
    "z1 = encoder(expect_im.squeeze(), lr=0.01, iterations=200, plot_losses=True, steps=10)\n",
    "assert z1.shape == (1, 512)\n",
    "\n",
    "# use noise to create reconstructed image\n",
    "class_encoding = get_one_hot_labels(torch.as_tensor([idx]), 36)\n",
    "combined_latent = combine_vectors(z1, class_encoding)\n",
    "im_reconstruction = gan_model(combined_latent)[-1].squeeze()\n",
    "image_adjustor = conditional_msggan.Generator.adjust_dynamic_range\n",
    "im_reconstruction = image_adjustor(im_reconstruction)\n",
    "\n",
    "# plot image vs its gan reconstruction\n",
    "# plt.figure()\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(expect_im.numpy().squeeze(), plt.cm.gray)\n",
    "# plt.title(\"Target Image\"), plt.axis(\"off\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(im_reconstruction.detach().cpu().numpy(), plt.cm.gray)\n",
    "# plt.title(\"Generated Image\"), plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1399)\n",
    "_, _, expect_im, idx = dataset[500]\n",
    "from torchvision import transforms\n",
    "expect_im = transforms.RandomHorizontalFlip(p=1)(expect_im)\n",
    "encoder = ImageEncoder(idx=idx, n_classes=36, decoder_model=gan_model, device=\"cuda:1\")\n",
    "z2 = encoder(expect_im.squeeze(), lr=0.05, iterations=2000, plot_losses=True, steps=250)\n",
    "assert z2.shape == (1, 512)\n",
    "\n",
    "# use noise to create reconstructed image\n",
    "class_encoding = get_one_hot_labels(torch.as_tensor([idx]), 36)\n",
    "combined_latent = combine_vectors(z2, class_encoding)\n",
    "im_reconstruction = gan_model(combined_latent)[-1].squeeze()\n",
    "image_adjustor = conditional_msggan.Generator.adjust_dynamic_range\n",
    "im_reconstruction = image_adjustor(im_reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117e8fa",
   "metadata": {},
   "source": [
    "## Can the GAN reconstruct its own image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1399)\n",
    "\n",
    "idx, n_classes = 10, 36\n",
    "\n",
    "# obtain true \n",
    "noise_true = torch.randn(1, 512)\n",
    "class_encoding = get_one_hot_labels(torch.tensor([idx]), n_classes)\n",
    "synthetic_im = gan_model(combine_vectors(noise_true, class_encoding))[-1]\n",
    "\n",
    "# reconstruct \n",
    "encoder = ImageEncoder(idx=idx, n_classes=n_classes, decoder_model=gan_model, device=\"cuda:1\")\n",
    "noise_expected = encoder(synthetic_im.squeeze(), lr=0.01, iterations=1000, plot_losses=True, steps=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d8581",
   "metadata": {},
   "source": [
    "## Differentiate left vs right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6272078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ceeb974",
   "metadata": {},
   "source": [
    "## Generate some random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a set of noise vectors\n",
    "n_samples = 50\n",
    "noise = get_noise(n_samples, 512)\n",
    "labels = torch.tensor(n_samples*[dataset.class2idx[\"ABCA4\"]])\n",
    "one_hot_labels = get_one_hot_labels(labels, dataset.n_classes)\n",
    "noise_and_labels = combine_vectors(noise, one_hot_labels)\n",
    "with torch.no_grad():\n",
    "    generated_images = gan_model(noise_and_labels)[-1]\n",
    "\n",
    "image_adjustor = conditional_msggan.Generator.adjust_dynamic_range\n",
    "generated_images = image_adjustor(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fe22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize images\n",
    "plt.figure(figsize=(12, 12))\n",
    "_ = show_tensor_images(generated_images, normalize=False, show_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65012f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_folder = \"results/gif_imgs/\"\n",
    "# os.makedirs(save_folder, exist_ok=True)\n",
    "# for i in range(len(generated_images)):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.axis('off')\n",
    "#     _ = show_tensor_images(generated_images[i], normalize=False, show_image=True, save_path=save_folder+\"res_{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9dd7a",
   "metadata": {},
   "source": [
    "## Exploring the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72719e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "right_eyes = [2, 7, 9, 10, 12, 15, 17, 20, 21, 23, 27, 30, 36, 38, 46, 47]\n",
    "left_eyes = [0, 1, 3, 4, 8, 11, 13, 16, 18, 26, 29, 32, 33, 37, 40, 41, 42, 45, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8fdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize indexes below to confirm correct features are used\n",
    "_ = show_tensor_images(generated_images[left_eyes], normalize=False, show_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the significantly different elements of right vs left eyes\n",
    "latents_right = noise_and_labels[right_eyes] \n",
    "latents_left = noise_and_labels[left_eyes]\n",
    "print(latents_right.shape, latents_left.shape)\n",
    "_, pval = ttest_ind(latents_right[:, :512], latents_left[:, :512], axis=0)\n",
    "sig_dif_idxs = np.concatenate((np.where(pval == np.min(pval), 1, 0), np.zeros(36)))[None, :]\n",
    "laterality = (torch.mean(latents_left, dim=0)[None, :] - torch.mean(latents_right, dim=0)[None, :]) * sig_dif_idxs\n",
    "laterality = laterality.type(torch.FloatTensor)\n",
    "print(\"Components that affect laterality = {}\".format(np.where(pval == np.min(pval))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize components\n",
    "avg_right = torch.mean(latents_right, dim=0)\n",
    "avg_left = torch.mean(latents_left, dim=0)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(x = np.arange(len(avg_right)), height = avg_right)\n",
    "plt.bar(x = np.arange(len(avg_right)), height = avg_right*sig_dif_idxs.squeeze())\n",
    "plt.xlim(-10, 548)\n",
    "plt.title(\"Right Eye Average Latent\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(x=np.arange(len(avg_left)), height=avg_left)\n",
    "plt.bar(x = np.arange(len(avg_left)), height = avg_left*sig_dif_idxs.squeeze())\n",
    "plt.xlim(-10, 548)\n",
    "plt.title(\"Left Eye Average Latent\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(x=np.arange(len(avg_right)), height=(avg_left - avg_right), color=\"black\")\n",
    "plt.bar(x=np.arange(len(avg_right)), height=(avg_left - avg_right)*sig_dif_idxs.squeeze(), color=\"red\")\n",
    "plt.title(\"Difference in Right vs Left Latent\")\n",
    "\n",
    "plt.xlim(-10, 548)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb801a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the laterality difference to a sample left image\n",
    "sample_left = 0\n",
    "factor = -100\n",
    "transformed_latent = noise_and_labels[sample_left][None, :] + factor*laterality\n",
    "with torch.no_grad():\n",
    "    tranformed_image = gan_model(transformed_latent)[-1]\n",
    "    \n",
    "# visualize difference\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(generated_images[sample_left].cpu().numpy().squeeze(), plt.cm.gray)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(tranformed_image.cpu().numpy().squeeze(), plt.cm.gray)\n",
    "plt.title(\"Image after adding feature\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b78ae5",
   "metadata": {},
   "source": [
    "## Interpolate between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f964a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolator = Interpolate(gan_model, interp=\"slerp\", component=\"classes\", n_classes=dataset.n_classes, n_interpolation=6, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = get_noise(1, 512, device)\n",
    "class1 = 'ABCA4'\n",
    "class2 = 'USH2A'\n",
    "class1_idx = torch.tensor([dataset.class2idx[class1]])\n",
    "class2_idx = torch.tensor([dataset.class2idx[class2]])\n",
    "interpolations = interpolator(noise, class1_idx, class2_idx)\n",
    "image_adjustor = conditional_msggan.Generator.adjust_dynamic_range\n",
    "interpolations[-1] = image_adjustor(interpolations[-1])\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "_ = plt.axis('off')\n",
    "_ = show_tensor_images(interpolations[-1], n_rows=9, normalize=False, show_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_folder = \"results/gif_imgs_2/\"\n",
    "# os.makedirs(save_folder, exist_ok=True)\n",
    "# for i in range(len(interpolations[-1])):\n",
    "# #     plt.figure(figsize=(6, 6))\n",
    "#     plt.axis('off')\n",
    "#     _ = show_tensor_images(interpolations[-1][i], normalize=False, show_image=True, save_path=save_folder+\"res_{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103cb0a",
   "metadata": {},
   "source": [
    "## Interpolate between noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e411024",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolator = Interpolate(gan_model, interp=\"slerp\", component=\"latents\", n_classes=dataset.n_classes, n_interpolation=6, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'ABCA4'\n",
    "class_idx = torch.tensor([dataset.class2idx[label]])\n",
    "latent1 = get_noise(1, z_dim, device)\n",
    "latent2 = get_noise(1, z_dim, device)\n",
    "interpolations = interpolator(latent1, latent2, class_idx)\n",
    "image_adjustor = conditional_msggan.Generator.adjust_dynamic_range\n",
    "interpolations[-1] = image_adjustor(interpolations[-1])\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "_ = plt.axis('off')\n",
    "_ = show_tensor_images(interpolations[-1], n_rows=9, normalize=False, show_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c77a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
